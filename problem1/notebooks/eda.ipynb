{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45021c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Import necessary libraries\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset from the Hugging Face Hub\n",
    "dataset = load_dataset(\"timm/mini-imagenet\")\n",
    "\n",
    "# The `dataset` object is a DatasetDict containing the splits\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8556b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecda3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN SET:\n",
      "Total number of classes: 100\n",
      "Number of samples per class:\n",
      "Class 0: 500 samples\n",
      "Class 1: 500 samples\n",
      "Class 2: 500 samples\n",
      "Class 3: 500 samples\n",
      "Class 4: 500 samples\n",
      "Class 5: 500 samples\n",
      "Class 6: 500 samples\n",
      "Class 7: 500 samples\n",
      "Class 8: 500 samples\n",
      "Class 9: 500 samples\n",
      "Class 10: 500 samples\n",
      "Class 11: 500 samples\n",
      "Class 12: 500 samples\n",
      "Class 13: 500 samples\n",
      "Class 14: 500 samples\n",
      "Class 15: 500 samples\n",
      "Class 16: 500 samples\n",
      "Class 17: 500 samples\n",
      "Class 18: 500 samples\n",
      "Class 19: 500 samples\n",
      "Class 20: 500 samples\n",
      "Class 21: 500 samples\n",
      "Class 22: 500 samples\n",
      "Class 23: 500 samples\n",
      "Class 24: 500 samples\n",
      "Class 25: 500 samples\n",
      "Class 26: 500 samples\n",
      "Class 27: 500 samples\n",
      "Class 28: 500 samples\n",
      "Class 29: 500 samples\n",
      "Class 30: 500 samples\n",
      "Class 31: 500 samples\n",
      "Class 32: 500 samples\n",
      "Class 33: 500 samples\n",
      "Class 34: 500 samples\n",
      "Class 35: 500 samples\n",
      "Class 36: 500 samples\n",
      "Class 37: 500 samples\n",
      "Class 38: 500 samples\n",
      "Class 39: 500 samples\n",
      "Class 40: 500 samples\n",
      "Class 41: 500 samples\n",
      "Class 42: 500 samples\n",
      "Class 43: 500 samples\n",
      "Class 44: 500 samples\n",
      "Class 45: 500 samples\n",
      "Class 46: 500 samples\n",
      "Class 47: 500 samples\n",
      "Class 48: 500 samples\n",
      "Class 49: 500 samples\n",
      "Class 50: 500 samples\n",
      "Class 51: 500 samples\n",
      "Class 52: 500 samples\n",
      "Class 53: 500 samples\n",
      "Class 54: 500 samples\n",
      "Class 55: 500 samples\n",
      "Class 56: 500 samples\n",
      "Class 57: 500 samples\n",
      "Class 58: 500 samples\n",
      "Class 59: 500 samples\n",
      "Class 60: 500 samples\n",
      "Class 61: 500 samples\n",
      "Class 62: 500 samples\n",
      "Class 63: 500 samples\n",
      "Class 64: 500 samples\n",
      "Class 65: 500 samples\n",
      "Class 66: 500 samples\n",
      "Class 67: 500 samples\n",
      "Class 68: 500 samples\n",
      "Class 69: 500 samples\n",
      "Class 70: 500 samples\n",
      "Class 71: 500 samples\n",
      "Class 72: 500 samples\n",
      "Class 73: 500 samples\n",
      "Class 74: 500 samples\n",
      "Class 75: 500 samples\n",
      "Class 76: 500 samples\n",
      "Class 77: 500 samples\n",
      "Class 78: 500 samples\n",
      "Class 79: 500 samples\n",
      "Class 80: 500 samples\n",
      "Class 81: 500 samples\n",
      "Class 82: 500 samples\n",
      "Class 83: 500 samples\n",
      "Class 84: 500 samples\n",
      "Class 85: 500 samples\n",
      "Class 86: 500 samples\n",
      "Class 87: 500 samples\n",
      "Class 88: 500 samples\n",
      "Class 89: 500 samples\n",
      "Class 90: 500 samples\n",
      "Class 91: 500 samples\n",
      "Class 92: 500 samples\n",
      "Class 93: 500 samples\n",
      "Class 94: 500 samples\n",
      "Class 95: 500 samples\n",
      "Class 96: 500 samples\n",
      "Class 97: 500 samples\n",
      "Class 98: 500 samples\n",
      "Class 99: 500 samples\n",
      "\n",
      "VALIDATION SET:\n",
      "Total number of classes: 100\n",
      "Number of samples per class:\n",
      "Class 0: 100 samples\n",
      "Class 1: 100 samples\n",
      "Class 2: 100 samples\n",
      "Class 3: 100 samples\n",
      "Class 4: 100 samples\n",
      "Class 5: 100 samples\n",
      "Class 6: 100 samples\n",
      "Class 7: 100 samples\n",
      "Class 8: 100 samples\n",
      "Class 9: 100 samples\n",
      "Class 10: 100 samples\n",
      "Class 11: 100 samples\n",
      "Class 12: 100 samples\n",
      "Class 13: 100 samples\n",
      "Class 14: 100 samples\n",
      "Class 15: 100 samples\n",
      "Class 16: 100 samples\n",
      "Class 17: 100 samples\n",
      "Class 18: 100 samples\n",
      "Class 19: 100 samples\n",
      "Class 20: 100 samples\n",
      "Class 21: 100 samples\n",
      "Class 22: 100 samples\n",
      "Class 23: 100 samples\n",
      "Class 24: 100 samples\n",
      "Class 25: 100 samples\n",
      "Class 26: 100 samples\n",
      "Class 27: 100 samples\n",
      "Class 28: 100 samples\n",
      "Class 29: 100 samples\n",
      "Class 30: 100 samples\n",
      "Class 31: 100 samples\n",
      "Class 32: 100 samples\n",
      "Class 33: 100 samples\n",
      "Class 34: 100 samples\n",
      "Class 35: 100 samples\n",
      "Class 36: 100 samples\n",
      "Class 37: 100 samples\n",
      "Class 38: 100 samples\n",
      "Class 39: 100 samples\n",
      "Class 40: 100 samples\n",
      "Class 41: 100 samples\n",
      "Class 42: 100 samples\n",
      "Class 43: 100 samples\n",
      "Class 44: 100 samples\n",
      "Class 45: 100 samples\n",
      "Class 46: 100 samples\n",
      "Class 47: 100 samples\n",
      "Class 48: 100 samples\n",
      "Class 49: 100 samples\n",
      "Class 50: 100 samples\n",
      "Class 51: 100 samples\n",
      "Class 52: 100 samples\n",
      "Class 53: 100 samples\n",
      "Class 54: 100 samples\n",
      "Class 55: 100 samples\n",
      "Class 56: 100 samples\n",
      "Class 57: 100 samples\n",
      "Class 58: 100 samples\n",
      "Class 59: 100 samples\n",
      "Class 60: 100 samples\n",
      "Class 61: 100 samples\n",
      "Class 62: 100 samples\n",
      "Class 63: 100 samples\n",
      "Class 64: 100 samples\n",
      "Class 65: 100 samples\n",
      "Class 66: 100 samples\n",
      "Class 67: 100 samples\n",
      "Class 68: 100 samples\n",
      "Class 69: 100 samples\n",
      "Class 70: 100 samples\n",
      "Class 71: 100 samples\n",
      "Class 72: 100 samples\n",
      "Class 73: 100 samples\n",
      "Class 74: 100 samples\n",
      "Class 75: 100 samples\n",
      "Class 76: 100 samples\n",
      "Class 77: 100 samples\n",
      "Class 78: 100 samples\n",
      "Class 79: 100 samples\n",
      "Class 80: 100 samples\n",
      "Class 81: 100 samples\n",
      "Class 82: 100 samples\n",
      "Class 83: 100 samples\n",
      "Class 84: 100 samples\n",
      "Class 85: 100 samples\n",
      "Class 86: 100 samples\n",
      "Class 87: 100 samples\n",
      "Class 88: 100 samples\n",
      "Class 89: 100 samples\n",
      "Class 90: 100 samples\n",
      "Class 91: 100 samples\n",
      "Class 92: 100 samples\n",
      "Class 93: 100 samples\n",
      "Class 94: 100 samples\n",
      "Class 95: 100 samples\n",
      "Class 96: 100 samples\n",
      "Class 97: 100 samples\n",
      "Class 98: 100 samples\n",
      "Class 99: 100 samples\n",
      "\n",
      "TEST SET:\n",
      "Total number of classes: 100\n",
      "Number of samples per class:\n",
      "Class 0: 50 samples\n",
      "Class 1: 50 samples\n",
      "Class 2: 50 samples\n",
      "Class 3: 50 samples\n",
      "Class 4: 50 samples\n",
      "Class 5: 50 samples\n",
      "Class 6: 50 samples\n",
      "Class 7: 50 samples\n",
      "Class 8: 50 samples\n",
      "Class 9: 50 samples\n",
      "Class 10: 50 samples\n",
      "Class 11: 50 samples\n",
      "Class 12: 50 samples\n",
      "Class 13: 50 samples\n",
      "Class 14: 50 samples\n",
      "Class 15: 50 samples\n",
      "Class 16: 50 samples\n",
      "Class 17: 50 samples\n",
      "Class 18: 50 samples\n",
      "Class 19: 50 samples\n",
      "Class 20: 50 samples\n",
      "Class 21: 50 samples\n",
      "Class 22: 50 samples\n",
      "Class 23: 50 samples\n",
      "Class 24: 50 samples\n",
      "Class 25: 50 samples\n",
      "Class 26: 50 samples\n",
      "Class 27: 50 samples\n",
      "Class 28: 50 samples\n",
      "Class 29: 50 samples\n",
      "Class 30: 50 samples\n",
      "Class 31: 50 samples\n",
      "Class 32: 50 samples\n",
      "Class 33: 50 samples\n",
      "Class 34: 50 samples\n",
      "Class 35: 50 samples\n",
      "Class 36: 50 samples\n",
      "Class 37: 50 samples\n",
      "Class 38: 50 samples\n",
      "Class 39: 50 samples\n",
      "Class 40: 50 samples\n",
      "Class 41: 50 samples\n",
      "Class 42: 50 samples\n",
      "Class 43: 50 samples\n",
      "Class 44: 50 samples\n",
      "Class 45: 50 samples\n",
      "Class 46: 50 samples\n",
      "Class 47: 50 samples\n",
      "Class 48: 50 samples\n",
      "Class 49: 50 samples\n",
      "Class 50: 50 samples\n",
      "Class 51: 50 samples\n",
      "Class 52: 50 samples\n",
      "Class 53: 50 samples\n",
      "Class 54: 50 samples\n",
      "Class 55: 50 samples\n",
      "Class 56: 50 samples\n",
      "Class 57: 50 samples\n",
      "Class 58: 50 samples\n",
      "Class 59: 50 samples\n",
      "Class 60: 50 samples\n",
      "Class 61: 50 samples\n",
      "Class 62: 50 samples\n",
      "Class 63: 50 samples\n",
      "Class 64: 50 samples\n",
      "Class 65: 50 samples\n",
      "Class 66: 50 samples\n",
      "Class 67: 50 samples\n",
      "Class 68: 50 samples\n",
      "Class 69: 50 samples\n",
      "Class 70: 50 samples\n",
      "Class 71: 50 samples\n",
      "Class 72: 50 samples\n",
      "Class 73: 50 samples\n",
      "Class 74: 50 samples\n",
      "Class 75: 50 samples\n",
      "Class 76: 50 samples\n",
      "Class 77: 50 samples\n",
      "Class 78: 50 samples\n",
      "Class 79: 50 samples\n",
      "Class 80: 50 samples\n",
      "Class 81: 50 samples\n",
      "Class 82: 50 samples\n",
      "Class 83: 50 samples\n",
      "Class 84: 50 samples\n",
      "Class 85: 50 samples\n",
      "Class 86: 50 samples\n",
      "Class 87: 50 samples\n",
      "Class 88: 50 samples\n",
      "Class 89: 50 samples\n",
      "Class 90: 50 samples\n",
      "Class 91: 50 samples\n",
      "Class 92: 50 samples\n",
      "Class 93: 50 samples\n",
      "Class 94: 50 samples\n",
      "Class 95: 50 samples\n",
      "Class 96: 50 samples\n",
      "Class 97: 50 samples\n",
      "Class 98: 50 samples\n",
      "Class 99: 50 samples\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# Function to perform EDA on a dataset split\n",
    "def eda_on_split(split_name, split_dataset):\n",
    "    labels = split_dataset['label']\n",
    "    label_counts = Counter(labels)\n",
    "    num_classes = len(label_counts)\n",
    "    print(f\"\\n{split_name.upper()} SET:\")\n",
    "    print(f\"Total number of classes: {num_classes}\")\n",
    "    print(\"Number of samples per class:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "# Perform EDA on each split\n",
    "eda_on_split(\"train\", train_dataset)\n",
    "eda_on_split(\"validation\", val_dataset)\n",
    "eda_on_split(\"test\", test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec36c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN SET - IMAGE SIZE DISTRIBUTION:\n",
      "Image sizes found in first 100 samples:\n",
      "  (307, 299): 1 images\n",
      "  (333, 500): 1 images\n",
      "  (344, 500): 1 images\n",
      "  (357, 500): 1 images\n",
      "  (358, 500): 1 images\n",
      "  (375, 500): 3 images\n",
      "  (378, 500): 1 images\n",
      "  (381, 500): 1 images\n",
      "  (382, 500): 1 images\n",
      "  (388, 500): 1 images\n",
      "  (399, 500): 2 images\n",
      "  (400, 500): 1 images\n",
      "  (407, 500): 1 images\n",
      "  (425, 500): 1 images\n",
      "  (426, 500): 1 images\n",
      "  (428, 500): 1 images\n",
      "  (438, 500): 1 images\n",
      "  (459, 500): 1 images\n",
      "  (460, 500): 1 images\n",
      "  (464, 500): 1 images\n",
      "  (469, 500): 1 images\n",
      "  (475, 500): 1 images\n",
      "  (476, 500): 1 images\n",
      "  (498, 500): 1 images\n",
      "  (499, 500): 1 images\n",
      "  (500, 312): 1 images\n",
      "  (500, 333): 3 images\n",
      "  (500, 334): 2 images\n",
      "  (500, 348): 1 images\n",
      "  (500, 354): 1 images\n",
      "  (500, 356): 1 images\n",
      "  (500, 357): 1 images\n",
      "  (500, 358): 1 images\n",
      "  (500, 359): 1 images\n",
      "  (500, 361): 1 images\n",
      "  (500, 363): 1 images\n",
      "  (500, 367): 1 images\n",
      "  (500, 368): 1 images\n",
      "  (500, 370): 4 images\n",
      "  (500, 372): 1 images\n",
      "  (500, 374): 1 images\n",
      "  (500, 375): 14 images\n",
      "  (500, 376): 1 images\n",
      "  (500, 379): 2 images\n",
      "  (500, 386): 2 images\n",
      "  (500, 387): 1 images\n",
      "  (500, 389): 1 images\n",
      "  (500, 390): 1 images\n",
      "  (500, 393): 1 images\n",
      "  (500, 394): 2 images\n",
      "  (500, 397): 1 images\n",
      "  (500, 399): 1 images\n",
      "  (500, 400): 2 images\n",
      "  (500, 409): 1 images\n",
      "  (500, 411): 1 images\n",
      "  (500, 416): 2 images\n",
      "  (500, 419): 1 images\n",
      "  (500, 431): 1 images\n",
      "  (500, 437): 1 images\n",
      "  (500, 438): 1 images\n",
      "  (500, 446): 1 images\n",
      "  (500, 447): 1 images\n",
      "  (500, 454): 1 images\n",
      "  (500, 474): 1 images\n",
      "  (500, 475): 1 images\n",
      "  (500, 477): 1 images\n",
      "  (500, 480): 1 images\n",
      "  (500, 483): 1 images\n",
      "  (500, 486): 1 images\n",
      "  (500, 500): 1 images\n",
      "  (600, 508): 1 images\n",
      "  (657, 599): 1 images\n",
      "  (800, 533): 1 images\n",
      "⚠ Images have varying sizes\n",
      "\n",
      "VALIDATION SET - IMAGE SIZE DISTRIBUTION:\n",
      "Image sizes found in first 100 samples:\n",
      "  (333, 500): 1 images\n",
      "  (357, 500): 1 images\n",
      "  (364, 500): 1 images\n",
      "  (372, 500): 2 images\n",
      "  (375, 500): 2 images\n",
      "  (378, 500): 1 images\n",
      "  (381, 500): 1 images\n",
      "  (396, 500): 1 images\n",
      "  (405, 285): 1 images\n",
      "  (419, 500): 1 images\n",
      "  (433, 500): 1 images\n",
      "  (448, 336): 1 images\n",
      "  (450, 552): 1 images\n",
      "  (460, 500): 1 images\n",
      "  (466, 500): 1 images\n",
      "  (471, 500): 1 images\n",
      "  (473, 500): 2 images\n",
      "  (483, 500): 2 images\n",
      "  (488, 500): 1 images\n",
      "  (491, 500): 1 images\n",
      "  (495, 448): 1 images\n",
      "  (495, 500): 1 images\n",
      "  (500, 304): 1 images\n",
      "  (500, 327): 1 images\n",
      "  (500, 333): 5 images\n",
      "  (500, 339): 1 images\n",
      "  (500, 348): 2 images\n",
      "  (500, 349): 1 images\n",
      "  (500, 354): 1 images\n",
      "  (500, 356): 2 images\n",
      "  (500, 357): 3 images\n",
      "  (500, 367): 1 images\n",
      "  (500, 372): 1 images\n",
      "  (500, 374): 1 images\n",
      "  (500, 375): 20 images\n",
      "  (500, 380): 3 images\n",
      "  (500, 389): 2 images\n",
      "  (500, 399): 2 images\n",
      "  (500, 400): 5 images\n",
      "  (500, 403): 1 images\n",
      "  (500, 410): 1 images\n",
      "  (500, 413): 1 images\n",
      "  (500, 416): 1 images\n",
      "  (500, 418): 1 images\n",
      "  (500, 427): 1 images\n",
      "  (500, 435): 1 images\n",
      "  (500, 439): 1 images\n",
      "  (500, 447): 1 images\n",
      "  (500, 448): 1 images\n",
      "  (500, 453): 1 images\n",
      "  (500, 454): 1 images\n",
      "  (500, 457): 1 images\n",
      "  (500, 460): 1 images\n",
      "  (500, 462): 1 images\n",
      "  (500, 467): 1 images\n",
      "  (500, 473): 1 images\n",
      "  (500, 488): 1 images\n",
      "  (500, 491): 1 images\n",
      "  (500, 500): 2 images\n",
      "  (640, 512): 1 images\n",
      "⚠ Images have varying sizes\n",
      "\n",
      "TEST SET - IMAGE SIZE DISTRIBUTION:\n",
      "Image sizes found in first 100 samples:\n",
      "  (333, 500): 1 images\n",
      "  (357, 500): 1 images\n",
      "  (364, 500): 1 images\n",
      "  (372, 500): 2 images\n",
      "  (375, 500): 2 images\n",
      "  (378, 500): 1 images\n",
      "  (381, 500): 1 images\n",
      "  (396, 500): 1 images\n",
      "  (405, 285): 1 images\n",
      "  (419, 500): 1 images\n",
      "  (433, 500): 1 images\n",
      "  (448, 336): 1 images\n",
      "  (450, 552): 1 images\n",
      "  (460, 500): 1 images\n",
      "  (466, 500): 1 images\n",
      "  (471, 500): 1 images\n",
      "  (473, 500): 2 images\n",
      "  (483, 500): 2 images\n",
      "  (488, 500): 1 images\n",
      "  (491, 500): 1 images\n",
      "  (495, 448): 1 images\n",
      "  (495, 500): 1 images\n",
      "  (500, 304): 1 images\n",
      "  (500, 327): 1 images\n",
      "  (500, 333): 5 images\n",
      "  (500, 339): 1 images\n",
      "  (500, 348): 2 images\n",
      "  (500, 349): 1 images\n",
      "  (500, 354): 1 images\n",
      "  (500, 356): 2 images\n",
      "  (500, 357): 3 images\n",
      "  (500, 367): 1 images\n",
      "  (500, 372): 1 images\n",
      "  (500, 374): 1 images\n",
      "  (500, 375): 20 images\n",
      "  (500, 380): 3 images\n",
      "  (500, 389): 2 images\n",
      "  (500, 399): 2 images\n",
      "  (500, 400): 5 images\n",
      "  (500, 403): 1 images\n",
      "  (500, 410): 1 images\n",
      "  (500, 413): 1 images\n",
      "  (500, 416): 1 images\n",
      "  (500, 418): 1 images\n",
      "  (500, 427): 1 images\n",
      "  (500, 435): 1 images\n",
      "  (500, 439): 1 images\n",
      "  (500, 447): 1 images\n",
      "  (500, 448): 1 images\n",
      "  (500, 453): 1 images\n",
      "  (500, 454): 1 images\n",
      "  (500, 457): 1 images\n",
      "  (500, 460): 1 images\n",
      "  (500, 462): 1 images\n",
      "  (500, 467): 1 images\n",
      "  (500, 473): 1 images\n",
      "  (500, 488): 1 images\n",
      "  (500, 491): 1 images\n",
      "  (500, 500): 2 images\n",
      "  (640, 512): 1 images\n",
      "⚠ Images have varying sizes\n",
      "\n",
      "TEST SET - IMAGE SIZE DISTRIBUTION:\n",
      "Image sizes found in first 100 samples:\n",
      "  (375, 500): 2 images\n",
      "  (377, 500): 2 images\n",
      "  (382, 500): 1 images\n",
      "  (391, 500): 1 images\n",
      "  (400, 500): 5 images\n",
      "  (401, 500): 1 images\n",
      "  (403, 500): 1 images\n",
      "  (414, 500): 2 images\n",
      "  (418, 500): 1 images\n",
      "  (423, 500): 2 images\n",
      "  (426, 500): 1 images\n",
      "  (428, 500): 1 images\n",
      "  (435, 500): 1 images\n",
      "  (442, 500): 1 images\n",
      "  (452, 500): 3 images\n",
      "  (453, 500): 1 images\n",
      "  (458, 500): 2 images\n",
      "  (460, 500): 1 images\n",
      "  (469, 500): 1 images\n",
      "  (471, 500): 1 images\n",
      "  (472, 500): 2 images\n",
      "  (477, 500): 1 images\n",
      "  (479, 500): 2 images\n",
      "  (491, 500): 1 images\n",
      "  (492, 500): 1 images\n",
      "  (493, 500): 1 images\n",
      "  (500, 375): 6 images\n",
      "  (500, 380): 1 images\n",
      "  (500, 381): 2 images\n",
      "  (500, 382): 1 images\n",
      "  (500, 384): 1 images\n",
      "  (500, 386): 1 images\n",
      "  (500, 389): 1 images\n",
      "  (500, 393): 1 images\n",
      "  (500, 395): 1 images\n",
      "  (500, 399): 1 images\n",
      "  (500, 400): 4 images\n",
      "  (500, 401): 2 images\n",
      "  (500, 402): 2 images\n",
      "  (500, 403): 1 images\n",
      "  (500, 404): 1 images\n",
      "  (500, 418): 1 images\n",
      "  (500, 422): 1 images\n",
      "  (500, 425): 1 images\n",
      "  (500, 427): 2 images\n",
      "  (500, 428): 2 images\n",
      "  (500, 429): 1 images\n",
      "  (500, 431): 1 images\n",
      "  (500, 432): 1 images\n",
      "  (500, 435): 2 images\n",
      "  (500, 438): 2 images\n",
      "  (500, 439): 2 images\n",
      "  (500, 446): 1 images\n",
      "  (500, 455): 2 images\n",
      "  (500, 456): 1 images\n",
      "  (500, 458): 1 images\n",
      "  (500, 460): 1 images\n",
      "  (500, 464): 1 images\n",
      "  (500, 466): 1 images\n",
      "  (500, 467): 1 images\n",
      "  (500, 470): 1 images\n",
      "  (500, 492): 1 images\n",
      "  (500, 493): 1 images\n",
      "  (500, 500): 7 images\n",
      "⚠ Images have varying sizes\n",
      "Image sizes found in first 100 samples:\n",
      "  (375, 500): 2 images\n",
      "  (377, 500): 2 images\n",
      "  (382, 500): 1 images\n",
      "  (391, 500): 1 images\n",
      "  (400, 500): 5 images\n",
      "  (401, 500): 1 images\n",
      "  (403, 500): 1 images\n",
      "  (414, 500): 2 images\n",
      "  (418, 500): 1 images\n",
      "  (423, 500): 2 images\n",
      "  (426, 500): 1 images\n",
      "  (428, 500): 1 images\n",
      "  (435, 500): 1 images\n",
      "  (442, 500): 1 images\n",
      "  (452, 500): 3 images\n",
      "  (453, 500): 1 images\n",
      "  (458, 500): 2 images\n",
      "  (460, 500): 1 images\n",
      "  (469, 500): 1 images\n",
      "  (471, 500): 1 images\n",
      "  (472, 500): 2 images\n",
      "  (477, 500): 1 images\n",
      "  (479, 500): 2 images\n",
      "  (491, 500): 1 images\n",
      "  (492, 500): 1 images\n",
      "  (493, 500): 1 images\n",
      "  (500, 375): 6 images\n",
      "  (500, 380): 1 images\n",
      "  (500, 381): 2 images\n",
      "  (500, 382): 1 images\n",
      "  (500, 384): 1 images\n",
      "  (500, 386): 1 images\n",
      "  (500, 389): 1 images\n",
      "  (500, 393): 1 images\n",
      "  (500, 395): 1 images\n",
      "  (500, 399): 1 images\n",
      "  (500, 400): 4 images\n",
      "  (500, 401): 2 images\n",
      "  (500, 402): 2 images\n",
      "  (500, 403): 1 images\n",
      "  (500, 404): 1 images\n",
      "  (500, 418): 1 images\n",
      "  (500, 422): 1 images\n",
      "  (500, 425): 1 images\n",
      "  (500, 427): 2 images\n",
      "  (500, 428): 2 images\n",
      "  (500, 429): 1 images\n",
      "  (500, 431): 1 images\n",
      "  (500, 432): 1 images\n",
      "  (500, 435): 2 images\n",
      "  (500, 438): 2 images\n",
      "  (500, 439): 2 images\n",
      "  (500, 446): 1 images\n",
      "  (500, 455): 2 images\n",
      "  (500, 456): 1 images\n",
      "  (500, 458): 1 images\n",
      "  (500, 460): 1 images\n",
      "  (500, 464): 1 images\n",
      "  (500, 466): 1 images\n",
      "  (500, 467): 1 images\n",
      "  (500, 470): 1 images\n",
      "  (500, 492): 1 images\n",
      "  (500, 493): 1 images\n",
      "  (500, 500): 7 images\n",
      "⚠ Images have varying sizes\n"
     ]
    }
   ],
   "source": [
    "# Analyze image size distribution\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def analyze_image_sizes(split_name, split_dataset):\n",
    "    \"\"\"Analyze image dimensions across a dataset split\"\"\"\n",
    "    image_sizes = defaultdict(int)\n",
    "    \n",
    "    print(f\"\\n{split_name.upper()} SET - IMAGE SIZE DISTRIBUTION:\")\n",
    "    \n",
    "    # Sample images to determine sizes (sample first 100 to be fast)\n",
    "    for i, sample in enumerate(split_dataset):\n",
    "        if i >= 100:  # Limit samples for speed\n",
    "            break\n",
    "        image = sample['image']\n",
    "        size = image.size  # PIL Image.size returns (width, height)\n",
    "        image_sizes[size] += 1\n",
    "    \n",
    "    print(f\"Image sizes found in first 100 samples:\")\n",
    "    for size, count in sorted(image_sizes.items()):\n",
    "        print(f\"  {size}: {count} images\")\n",
    "    \n",
    "    # Check if all images are the same size\n",
    "    if len(image_sizes) == 1:\n",
    "        size = list(image_sizes.keys())[0]\n",
    "        print(f\"✓ All images are uniform: {size[0]}×{size[1]} pixels\")\n",
    "    else:\n",
    "        print(f\"⚠ Images have varying sizes\")\n",
    "\n",
    "# Run analysis on each split\n",
    "analyze_image_sizes(\"train\", train_dataset)\n",
    "analyze_image_sizes(\"validation\", val_dataset)\n",
    "analyze_image_sizes(\"test\", test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fb016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
